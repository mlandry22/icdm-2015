{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from itertools import islice\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getIPDict(ip_file):\n",
    "\t\"\"\"\n",
    "    Using code provided by Sudalai :)\n",
    "    \n",
    "\tEach line in the IP file belongs to either a device or a cookie.\n",
    "\tThis function creates two dictionaries\n",
    "\t1. Device dictionary - has device_id as key and the IPs it belongs to as value in the form of list\n",
    "\t2. IP Dictionary - has IP address as the key and the cookies in that IP as value in the form of list\n",
    "\tReasoning:\n",
    "\tWe need to find the cookies that are associated with the given device in the competition. So given a device we can find out the IP addressess of the device from device dictionary. Then using those IP addresses and IP Dictionary, find out the cookies associated with the IP and link them back to the device.\n",
    "\t\"\"\"\n",
    "\t# reading the ip file #\n",
    "\treader = csv.reader(ip_file)\n",
    "\theader = reader.next()             # skipping the header\n",
    "\n",
    "\t# initializing the dicts #\n",
    "\tdevice_dict = {}\n",
    "\tip_dict = {}\n",
    "\n",
    "\tcounter = 0                        # counter to manage the progress\n",
    "\tfor row in reader:\n",
    "\t\tcounter += 1\n",
    "\n",
    "\t\t# extracting ip address alone from the given input and store it in a list #\n",
    "\t\tip_all_str = ','.join(row[2:]) \n",
    "\t\tip_list = []\n",
    "\t\tip_all_list = ip_all_str.replace(\"{\",\"\").replace(\"}\",\"\").replace(\"),(\",\" \").replace(\"(\",\"\").replace(\")\",\"\").split(\" \")     # formatting \n",
    "\t\tfor val in ip_all_list:\n",
    "\t\t\tip_list.append(val.split(\",\")[0])\n",
    "\n",
    "\t\t# if device, write to device dict, else write to ip dict #\n",
    "\t\tif row[1] == '0':\n",
    "\t\t\tdevice_dict[row[0]] = ip_list\n",
    "\t\telif row[1] == '1':\n",
    "\t\t\tfor ip in ip_list:\n",
    "\t\t\t\ttemp_list = ip_dict.get(ip,[])\n",
    "\t\t\t\ttemp_list.append(row[0])\n",
    "\t\t\t\tip_dict[ip] = temp_list\n",
    "\t\telse:\n",
    "\t\t\tprint \"Device or Cookie has unacceptable value.. Value : \", row[1]\n",
    "\t\t\traise\n",
    "\n",
    "\t\t# printing the progress #\n",
    "\t\tif counter % 50000 == 0:\n",
    "\t\t\tprint \"Processed : \", counter\n",
    "\t\t\t\n",
    "\treturn device_dict, ip_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notes...either alter the path to the data file or just do the lazy way of placing this notebook in the same folder\n",
    "# with the data\n",
    "\n",
    "# Load files that lend themselves to a dataframe...(un)commment the data frames as you need them.\n",
    "\n",
    "# Note..I think we could create sets and then do intersections on them to quickly collapse data frames...it's a ToDo\n",
    "# on my list.\n",
    "\n",
    "df_cookie_all_basic = pd.read_csv('cookie_all_basic.csv')\n",
    "#df_dev_test_basic = pd.read_csv('dev_test_basic.csv')\n",
    "#df_dev_train_basic = pd.read_csv('dev_train_basic.csv')\n",
    "#df_ipagg_all = pd.read_csv('ipagg_all.csv')\n",
    "#df_sample_submission = pd.read_csv('sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cookie_all_basic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file config #\n",
    "data_path = \"../Data/\"\n",
    "ip_file = open(\"id_all_ip.csv\")\n",
    "\n",
    "print \"Getting device and IP dict..\"\n",
    "device_dict, ip_dict = getIPDict(ip_file)\n",
    "\n",
    "df_device_dict = pd.DataFrame(list(device_dict.iteritems()), columns=['device_dict_key', 'device_dict_values'])\n",
    "\n",
    "df_ip_dict = pd.DataFrame(list(ip_dict.iteritems()), columns=['ip_dict_key', 'ip_dict_values'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell helps spit out the first 3 rows of the data frames for df_devices\n",
    "df_device_dict.head(3)\n",
    "df_ip_dict.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call this if you need to run a separate console to help debug or try functions\n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define/Declare functions here\n",
    "def getIPDict_2(ip_file):\n",
    "    \"\"\"\n",
    "    Fill in when done\n",
    "    \"\"\"\n",
    "    # reading the ip file #\n",
    "    reader = csv.reader(ip_file)\n",
    "    header = reader.next()             # skipping the header\n",
    "\n",
    "    # initializing the dicts #\n",
    "\n",
    "    property_dict = {}\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for row in reader:\n",
    "        counter += 1\n",
    "        #print(row[0])\n",
    "\n",
    "        id_all = row[0]\n",
    "        indicator = row[1]\n",
    "\n",
    "        prop_all_str = ','.join(row[2:])\n",
    "\n",
    "        prop_list = []\n",
    "        count_list = []\n",
    "\n",
    "        prop_all_list = prop_all_str.replace(\"{\",\"\").replace(\"}\",\"\").replace(\"),(\",\" \").replace(\"(\",\"\").replace(\")\",\"\").split(\" \")\n",
    "        #print(prop_all_list)\n",
    "\n",
    "        for val in prop_all_list:\n",
    "            prop_list.append(val.split(\",\")[0])\n",
    "            count_list.append(val.split(\",\")[1])\n",
    "\n",
    "        #print(prop_list)\n",
    "        #print(count_list)\n",
    "        \n",
    "        property_dict[id_all] = (indicator, prop_list, count_list)\n",
    "\n",
    "        # printing the progress #\n",
    "        if counter % 50000 == 0:\n",
    "            print \"Processed : \", counter\n",
    "\n",
    "    return property_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed :  50000\n",
      "Processed :  100000\n",
      "Processed :  150000\n",
      "Processed :  200000\n",
      "Processed :  250000\n",
      "Processed :  300000\n",
      "Processed :  350000\n",
      "Processed :  400000\n",
      "Processed :  450000\n",
      "Processed :  500000\n",
      "Processed :  550000\n",
      "Processed :  600000\n",
      "Processed :  650000\n",
      "Processed :  700000\n",
      "Processed :  750000\n",
      "Processed :  800000\n",
      "Processed :  850000\n",
      "Processed :  900000\n",
      "Processed :  950000\n",
      "Processed :  1000000\n",
      "Processed :  1050000\n",
      "Processed :  1100000\n",
      "Processed :  1150000\n",
      "Processed :  1200000\n",
      "Processed :  1250000\n",
      "Processed :  1300000\n",
      "Processed :  1350000\n",
      "Processed :  1400000\n",
      "Processed :  1450000\n",
      "Processed :  1500000\n",
      "Processed :  1550000\n",
      "Processed :  1600000\n",
      "Processed :  1650000\n",
      "Processed :  1700000\n",
      "Processed :  1750000\n",
      "Processed :  1800000\n",
      "Processed :  1850000\n",
      "Processed :  1900000\n",
      "Processed :  1950000\n",
      "Processed :  2000000\n",
      "Processed :  2050000\n",
      "Processed :  2100000\n",
      "Processed :  2150000\n"
     ]
    }
   ],
   "source": [
    "#ip_file = open(\"test.csv\")\n",
    "ip_file = open(\"id_all_property.csv\")\n",
    "test = getIPDict_2(ip_file)\n",
    "\n",
    "\n",
    "df_property_dict = pd.DataFrame(list(test.iteritems()), columns=['id_dict_key', 'prop_dict_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This data frame uses an iterator to go through each row within the data frame. It applies several things:\n",
    "# It creates a new column called 'total_sum' by using the apply method via lambda function.\n",
    "# It first takes the nested tuple, takes out the column with property count, changes it from a string to int\n",
    "# then it adds all the values togehter.\n",
    "\n",
    "\n",
    "df_property_dict['total_sum'] = df_property_dict.prop_dict_values.apply(lambda row: sum(map(int, row[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_dict_key</th>\n",
       "      <th>prop_dict_values</th>\n",
       "      <th>total_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> id_1684982</td>\n",
       "      <td> (0, [property_55876, property_490148, property...</td>\n",
       "      <td>  23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> id_4227995</td>\n",
       "      <td> (1, [property_264003, property_210052, propert...</td>\n",
       "      <td> 197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> id_4651263</td>\n",
       "      <td>                       (1, [property_168296], [1])</td>\n",
       "      <td>   1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_dict_key                                   prop_dict_values  total_sum\n",
       "0  id_1684982  (0, [property_55876, property_490148, property...         23\n",
       "1  id_4227995  (1, [property_264003, property_210052, propert...        197\n",
       "2  id_4651263                        (1, [property_168296], [1])          1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_property_dict.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Want to sort the data frame for id with highest property sum\n",
    "sort_id = df_property_dict(['total_sum'], ascending = [0])\n",
    "\n",
    "# This will return a data frame with all the id by total sum descending....modify the data frames as needed for other opterations\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
